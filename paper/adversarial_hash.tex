%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Template for USENIX papers.
%
% History:
%
% - TEMPLATE for Usenix papers, specifically to meet requirements of
%   USENIX '05. originally a template for producing IEEE-format
%   articles using LaTeX. written by Matthew Ward, CS Department,
%   Worcester Polytechnic Institute. adapted by David Beazley for his
%   excellent SWIG paper in Proceedings, Tcl 96. turned into a
%   smartass generic template by De Clarke, with thanks to both the
%   above pioneers. Use at your own risk. Complaints to /dev/null.
%   Make it two column with no page numbering, default is 10 point.
%
% - Munged by Fred Douglis <douglis@research.att.com> 10/97 to
%   separate the .sty file from the LaTeX source template, so that
%   people can more easily include the .sty file into an existing
%   document. Also changed to more closely follow the style guidelines
%   as represented by the Word sample file.
%
% - Note that since 2010, USENIX does not require endnotes. If you
%   want foot of page notes, don't include the endnotes package in the
%   usepackage command, below.
% - This version uses the latex2e styles, not the very ancient 2.09
%   stuff.
%
% - Updated July 2018: Text block size changed from 6.5" to 7"
%
% - Updated Dec 2018 for ATC'19:
%
%   * Revised text to pass HotCRP's auto-formatting check, with
%     hotcrp.settings.submission_form.body_font_size=10pt, and
%     hotcrp.settings.submission_form.line_height=12pt
%
%   * Switched from \endnote-s to \footnote-s to match Usenix's policy.
%
%   * \section* => \begin{abstract} ... \end{abstract}
%
%   * Make template self-contained in terms of bibtex entires, to allow
%     this file to be compiled. (And changing refs style to 'plain'.)
%
%   * Make template self-contained in terms of figures, to
%     allow this file to be compiled. 
%
%   * Added packages for hyperref, embedding fonts, and improving
%     appearance.
%   
%   * Removed outdated text.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix2019_v3}

% to be able to draw some self-contained figs
\usepackage{tikz}
\usetikzlibrary{crypto.symbols}
\tikzset{shadows=no} 
\usetikzlibrary{positioning}
\usetikzlibrary{shapes}
\usepackage{rotating} 
\usepackage{amsmath}

% inlined bib file
\usepackage{filecontents}

%-------------------------------------------------------------------------------
\begin{filecontents}{\jobname.bib}
%-------------------------------------------------------------------------------
@Book{arpachiDusseau18:osbook,
  author =       {Arpaci-Dusseau, Remzi H. and Arpaci-Dusseau Andrea C.},
  title =        {Operating Systems: Three Easy Pieces},
  publisher =    {Arpaci-Dusseau Books, LLC},
  year =         2015,
  edition =      {1.00},
  note =         {\url{http://pages.cs.wisc.edu/~remzi/OSTEP/}}
}
@InProceedings{waldspurger02,
  author =       {Waldspurger, Carl A.},
  title =        {Memory resource management in {VMware ESX} server},
  booktitle =    {USENIX Symposium on Operating System Design and
                  Implementation (OSDI)},
  year =         2002,
  pages =        {181--194},
  note =         {\url{https://www.usenix.org/legacy/event/osdi02/tech/waldspurger/waldspurger.pdf}}}
\end{filecontents}

%-------------------------------------------------------------------------------
\begin{document}
%-------------------------------------------------------------------------------

%don't want date printed
\date{}

% make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf Blackbox Adversarial Learning on Hash Functions}

%for single author (just remove % characters)
\author{
{\rm Anirban Gangopadhyay}\\
Your Institution
\and
{\rm Joshua Zweig}\\
Second Institution
% copy the following lines to add more authors
% \and
% {\rm Name}\\
%Name Institution
} % end author

\maketitle

%-------------------------------------------------------------------------------
\begin{abstract}
%-------------------------------------------------------------------------------
Your abstract text goes here. Just a few facts. Whet our appetites.
Not more than 200 words, if possible, and preferably closer to 150.

We present a novel machine learning framework which we apply here to uncover weaknesses in hash functions. Our framework extends the definition of adversarial learning to the domain of cryptographic systems. In this paper, we uncover weaknesses in Merkle?Damgard structured hash functions, which include MD5, SHA-1 and SHA-2 and are critical components of cryptographic systems such as key exchange, digital signatures, and password and file verification. Most attacks against these hash functions leverage properties of the particular function. We develop a broader framework of adversarial learning to probabilistically determine how a hash function differs from its ideal state. We show the efficacy of our framework by theoretically and empirically discovering known vulnerabilities in MD5 and discuss how our method can be applied to uncovering potential unknown weaknesses in other hash functions in the Merkle?Damgard class.
\end{abstract}

%-------------------------------------------------------------------------------
\section{Introduction}
%-------------------------------------------------------------------------------

Talk about the purpose of the paper. Emphasize how our work is novel. 
\\
\\
\textbf{Note:} Traditional adversarial learning is defined as a technique employed in the field of machine learning which attempts to fool models through malicious input. Our definition is slightly different so we need to be deliberate in explaining how our new definition still ties to this concept

\subsection{Related Work}
May or may not want this as a subsection. Including for now. 

%-------------------------------------------------------------------------------
\section{Contributions}
%-------------------------------------------------------------------------------
\begin{itemize}
\item Expand definition of adversarial learning to a broader class of problems 
\item Leverage this definition of adversarial learning to introduce a black box attack on hash functions of the Merkle construction 
\item Uncover vulnerabilities in MD5 with this methodology (TBD based on results how we'll frame this) 
\item Epsilon, Delta framing 
\end{itemize}

%-------------------------------------------------------------------------------
\section{Background}
%-------------------------------------------------------------------------------

Do we need this section in order for the paper to be self contained? 

%-------------------------------------------------------------------------------
\section{Adversarial Learning on Cryptographic Systems}
%-------------------------------------------------------------------------------

In this section we extend the definition of adversarial learning and explore its relevance in the context of cryptographic systems. We note that all cryptographic systems rely on the notion of randomness and intractability. Hence, by framing an adversarial set of examples as one that yields a reduction in entropy on the outputs, we set ourselves up to empirically discover inputs that violate the properties of cryptographic functions. 

\subsection{Adversarial Learning}
We start by presenting the notion of adversarial learning in the context of cryptographic systems. In our construction, we treat the system as a blackbox $B(\cdot)$ and consider the following problem of finding adversarial examples:
\\
\\
\textbf{Meta Problem:} Given a blackbox system $B(\cdot)$ that takes in as input $X: \{0,1\}^{M} \rightarrow Y$ (where $Y \in R^{N}$), can we find a subset $X_{adv}$ such that the error function $F_{\epsilon} (Y, Y_{adv} \}$ is large for some error function $F_{\epsilon}(\cdot )$ that measures a difference in entropy over the output sets.
\\
\\
We note that a reduction in entropy on the output set can be measured in different ways. Salient examples include a reduction in Shannon entropy on $\hat{Y}$, higher predictability of the distribution formed by $\hat{Y}$, or a parametrization of $\hat{Y}$ via a set of discriminating features.
\\
\\
The type of entropy reduction we use depends on the construction of our blackbox system $B(\cdot)$, and the specific properties of randomness we would like to exploit.  
\\
\\
We give specific definitions of $F_{\epsilon}(\cdot)$ for the examples discussed above. 
\begin{itemize}
\item Reduction in Shannon Entropy: We define $F_{\epsilon} (\cdot) = \frac{E[H(Y_{adv})]}{E[H(Y)]}$ where $H(Y) = -\sum_{i=1}^{n} P(y_{i}) log P(y_{i})$.  
\item Predictability of Distribution: We define $F_{\epsilon} (\cdot) = KL(Dist (\cdot) | P(Y_{adv}))$ where $KL(\cdot)$ represents KL divergence - a measure of distance between probability distributions, $Dist(\cdot)$ represents the distribution representing $P(Y_{adv})$. We note $P(Y_{adv})$ represents the probability distribution over the adversarial set. We also note $Dist(\cdot)$ must be nonuniform for our examples to be truly adversarial. 
\item Parametrization - We define $F_{\epsilon} (\cdot) = F_{\Theta}(X_{adv})$ where $\Theta$ represents a parametrization over the inputs, yielding the output set $Y_{adv}$.
\end{itemize}



Each definition of $F_{\epsilon}(\cdot)$ lends itself to various attack vectors that allow for the exploitation of $B(\cdot)$. Hence, we consider the class of adversarial examples to be inputs that enable entropy reductions such as the ones specified above. 

\subsection{Cryptographic Systems}
What does this look like in the context of PRNGs, public key generators, hash functions?

%-------------------------------------------------------------------------------
\section{Adversarial Learning on Hash Functions}
%-------------------------------------------------------------------------------

\textbf{Meta Problem for Hash Functions:} Can we quantify how much a hash function deviates from its ideal state (perfect one way function)?

\subsection{Notion of Blackbox}
Define w.r.t to threat model. This isn't zero knowledge, an attacker needs to know the construction is Merkle construction

- 

\subsection{Blackbox Definition}
\textcolor{red}{Define the blackbox. Explain how it is general enough due to Merkle process to apply to MD5, SHA1, SHA2}

\begin{figure}
\begin{center} 
\begin{tikzpicture}[scale=0.4]
%	\path[anchor=east] (-1,0.5) node {$pad(M)=$};
	\draw[thin,inner sep=2ex] (0,0) rectangle (16,1);

	%% Separations in the message
	\draw[thin] ++( 4,0) -- ++(0,1); \path (   2,0.5) node {$X_{0}$};
	\draw[thin] ++( 8,0) -- ++(0,1); \path ( 4+2,0.5) node {$X_{1}$};
	\draw[thin] ++(12,0) -- ++(0,1); \path ( 8+2,0.5) node {$X_{2}$};
	\draw[thin] ++(16,0) -- ++(0,1); \path (12+2,0.5) node {$X_{3}$};

	%% Compressions functions 
	\begin{scope}[shift={(0.5,-4)}]
		\node [draw,trapezium,trapezium left angle=70,trapezium right angle=70,minimum height=0.7cm,thin,shift={(1.15,0.4)},rotate=-90] 
		{\begin{sideways}\Large$f$\end{sideways}};
		\draw[->,thin] ++(1.5,+4) -- ++(0,-2.5) -- ++(0.5,0);
		\draw[->,thin] ++(0,0.5) node[left] {$S_{0}=IV$}-- ++(2,0);
	\end{scope}

	\begin{scope}[shift={(4.5,-4)}]
		\node [draw,trapezium,trapezium left angle=70,trapezium right angle=70,minimum height=0.7cm,thin,shift={(1.15,0.4)},rotate=-90] 
		{\begin{sideways}\Large$f$\end{sideways}};
		\draw[->,thin] ++(1.5,+4) -- ++(0,-2.5) -- ++(0.5,0);
		\draw[->,thin] ++(-0.2,0.5) -- node[below] {$S_{1}$} ++(2.2,0);
	\end{scope}

	\begin{scope}[shift={(8.5,-4)}]
		\node [draw,trapezium,trapezium left angle=70,trapezium right angle=70,minimum height=0.7cm,thin,shift={(1.15,0.4)},rotate=-90] 
		{\begin{sideways}\Large$f$\end{sideways}};
		\draw[->,thin] ++(1.5,+4) -- ++(0,-2.5) -- ++(0.5,0);
		\draw[->,thin] ++(-0.2,0.5) -- node[below] {$S_{2}$} ++(2.2,0);
	\end{scope}

	\begin{scope}[shift={(12.5,-4)}]
		\node [draw,trapezium,trapezium left angle=70,trapezium right angle=70,minimum height=0.7cm,thin,shift={(1.15,0.4)},rotate=-90] 
		{\begin{sideways}\Large$f$\end{sideways}};
		\draw[->,thin] ++(1.5,+4) -- ++(0,-2.5) -- ++(0.5,0);
		\draw[->,thin] ++(-0.2,0.5) -- node[below] {$h_{3}$} ++(2.2,0);
	\end{scope}

	\begin{scope}[shift={(16.5,-4)}]
		\draw[->,thin] ++(-0.2,0.5) -- ++(0.75,0) node[right] {$\cdots$} ;
	\end{scope}
\end{tikzpicture}
\end{center}
\caption{\label{fig:merkleconstruction} The Merkle{\textendash}Damg\r{a}rd construction of secure hash functions.}
\end{figure} 

\tikzstyle{block} = [draw, rectangle, minimum height=3em, minimum width=3em]
\tikzstyle{virtual} = [coordinate]
\tikzstyle{init} = [pin edge={to-,thin,black}]
\begin{center}
\begin{tikzpicture}[>=stealth,auto, node distance=3cm]
    \node [block, pin={[init]above:$X_{i-1}$}] (a) {$T^{p-1}$};
    \node (b) [left of=a,node distance=2cm, coordinate] {a};
    \path[->] (b) edge node {$S_{i-1}$} (a);
    \draw[->] (a.east)  -- node[above]{$S_i$} ++(4em,0em);
\end{tikzpicture}
\end{center}

For the Merkle{\textendash}Damg\r{a}rd class of hash functions, we define a singular blackbox component, $B$ as the function $S_i =  B(S_{i-1}, x_{i-1})$. We will outline was this definition is sufficient to model any Merkle{\textendash}Damg\r{a}rd function later in this section. 

We limit the scope of the empirical portion of our study to the Merkle{\textendash}Damg\r{a}rd class of hash functions, which includes MD5, SHA-1, and SHA-2. We limit the scope in this way to be able to give a definition for a blackbox component $B$ towards validating our framework, noting that our methods remain general and applicable to other contexts and for different definitions of $B$. 

The Merkle{\textendash}Damg\r{a}rd construction is detailed in Figure \ref{fig:merkleconstruction}. In this construction, some padding is applied on the input message to generate $X = X_0X_1X_2\cdots X_n$, where $n$ is the number of chunks the input is broken into. A function, $f$, is applied to each of these chunks, $X_i$ and also to the state information output from the previous step, $S_i$. The state is seeded in some way for any particular function conforming to the Merkle{\textendash}Damg\r{a}rd construction. The primary creativity any particular hash function can apply is in the definition of the seed, the padding function and the definition of $f$. Each particular hash function, though, must define some function $f$ which takes as an input a chunk of the input message $X_i$ and state information from the previous state and only the previous state, $S_i$, and output its own state information for consumption by the next application of $f$. We model the blackbox component $B(S_{i-1}, x_{i-1})$ to assume these properties and only these properties. The model remains agnostic to any particular padding function, seed, and especially definition of $f$ as defined by any conforming hash function, be it  MD5, SHA-1, or SHA-2. This implies that this methodology, unchanged, can be freely applied to any of these three hash functions towards analyzing their weaknesses. 


\subsection{Markov Process}
We discuss our machine learning framework which is designed to detect weaknesses in our blackbox function $B(\cdot)$ for Merkle{\textendash}Damg\r{a}rd structured hash functions. Our goal is to determine if a hash function is weak given an example set $X'$. We note that the states outlined in our framework are purely Markov states and dont represent any transform in the hash function itself. We specifically favor this blackbox construction since it generalizes to any Merkle Damgard hash construction. 
\\
\\
We denote the set of Markov states to be the complete set $(S_{i})$ such that $S_{i} \in \{0,1\}^{n}$ where $n$ varies by hash function. We parametrize this set within the context of blackbox components $B = \{B_{1},..., B_{N}\}$ where $N = 2^{n}$.  
\\
\\
A transition from $B_{i}$ to $B_{j}$ is represented as an input chunk-state pair $(S_{i-1}, X_{i})$ yielding the output state $S_{i}$.  
\\
\\
Given a set of inputs $X'$, we train our Markov states by considering the sequence of chunk transforms $S_{0} \rightarrow B^{1}(X_{i}, S_{i}) \rightarrow S_{1},..., \rightarrow S_{p-1} \rightarrow B^{P}(X_{i}, S_{i}) \rightarrow S_{p}$ where $P$ is the number of steps in a round of $B(\cdot)$ for each $X$. 
\\
\\
By using MLE estimates and applying the Markov assumption, we get $P(B^{i} | B^{j}) = \frac{count(B^{i}(X_{i}, S_{i}) \rightarrow S_{j})}{count(B^{i}(X_{i}, S_{i})}$. \textbf{Note:} Can provide proof if necessary
\\
\\
Hence, we can represent our Markov transition probabilities via a $N \times N'$ probability matrix where $N' = 2^{n}$, $N$ is defined as above.
\\
\\
Our goal is to identify given a set $\hat{X}$, whether $\frac{E[P(\hat{B})]}{E[P(B)]} < \epsilon$ for some predefined $\epsilon$. If so we denote $\hat{X}$ adversarial. 
\\
\\
We can define $P(B)$ as the Shannon entropy over the elements of the state transition matrix $S$. Specifically, we find the distribution of element values and then compute $H(S) = -\sum_{i=1}^{n} P(s_{i}) log P(s_{i})$.
\\
\\
Define the Markov process, how this can be used to identify weak hash functions. Tie in the generative discussion here
\\
\\
The current notion of a Markov state is defined as an input of a blackbox component ($\{0,1\}^{128})$. Can we define a state more coarsely (parametrized in some way). Ideas:
\begin{itemize}
\item Collapse Markov state in a cascading manner (Random forest analogy)
\end{itemize}

\subsection{Finding Adversarial Examples}
Define the sampling scheme for finding adversarial examples. 
\\
\\
First define Theorem 1 (state as the naive sampling method).
\\
\\
Then state our novel sampling method along with Theorem 2

\subsection{Finding Weak Hash Functions}
Here we outline our specific algorithms for finding:
\begin{itemize}
\item Collisions
\item Correlations
\item Preimage
\end{itemize}
The presentation of the algorithm should follow the following structure:
\begin{enumerate}
\item Provide a mathematical definition of the weakness
\item Outline the algorithm (using the one from previous section) for uncovering the weak property
\item Expected number of examples to uncover the weak property in a vulnerable hash function
\begin{itemize}
\item Consider the generative process or statistical properties that a given weakness enables
\end{itemize}
\end{enumerate}

\subsection{Validating Adversarial Examples}
Outline how domain based methods have uncovered specific weaknesses in MD5 (and if time SHA1), how to characterize the input and output sets of the weakness (show that the statistical properties that a given weakness described in the previous section apply), and how our algorithm ties to the same set of inputs and outputs (but using a completely different methodology)
\\
\\
Also describe how our algorithm is novel and can be applied to any hash function to test weakness. We simply validate this with MD5 (and perhaps SHA1)

%-------------------------------------------------------------------------------
\section{Results \& Applications}
%-------------------------------------------------------------------------------

\begin{enumerate}
\item Seed sampling algorithm with known collisions and see if other collisions are uncovered. Logic is based on the fact that tunneling properties provide necessary but not sufficient conditions for collisions 
\item Can test with SHA1 as well
\item Run the sampling scheme for different values of $\epsilon, \delta$ and see the collision rates, yields of $\hat{X}$
\item Derive $m$ for Theorem 1 given different values of $\epsilon, \delta$ and map that to reasonable CPU measures. Then test this empirically and validate our values of $\epsilon, \delta$ measure up empirically (Frame in terms of threat model) 
\item Run on known good hash functions (ie SHA256) and see what results we get
\end{enumerate}

\textbf{Figure out:} What charts do we want to show? How do we want to structure the results section in the most effective way possible? Options are: 

\begin{enumerate}
\item Table of $m, \epsilon, \delta$, CPU measures for naive algorithm, Theorem 2 alg, alg for uncovering each weakness
\item A chart of CPU/cores vs time it took to run
\item Can have bar charts that illustrate how many times (over N runs), we found a collision, etc
\item Replicate these for the case where we seed the sampling algorithm with known collisions
\end{enumerate}



%-------------------------------------------------------------------------------
\section*{Related Work}
%-------------------------------------------------------------------------------

Maybe we can work in sufficiently elsewhere 

%-------------------------------------------------------------------------------
\section*{Acknowledgments}
%-------------------------------------------------------------------------------

The USENIX latex style is old and very tired, which is why
there's no \textbackslash{}acks command for you to use when
acknowledging. Sorry.

%-------------------------------------------------------------------------------
\section*{Availability}
%-------------------------------------------------------------------------------

USENIX program committees give extra points to submissions that are
backed by artifacts that are publicly available. If you made your code
or data available, it's worth mentioning this fact in a dedicated
section.

%-------------------------------------------------------------------------------
\bibliographystyle{plain}
\bibliography{\jobname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%  LocalWords:  endnotes includegraphics fread ptr nobj noindent
%%  LocalWords:  pdflatex acks